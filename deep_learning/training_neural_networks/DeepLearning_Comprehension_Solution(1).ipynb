{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a845d97",
   "metadata": {
    "id": "mIEb3H8DUnjy"
   },
   "source": [
    "# Task 1 - Setup and Data Preparation\n",
    "For this task, you will:\n",
    "- Import necessary packages for executing the code\n",
    "- Install the EMNIST package\n",
    "- Load the EMINST (letters) data and study its basic features such as its shape\n",
    "- Convert the pixel gray levels of the images into the range [0,1]\n",
    "- One-hot encode the class labels in the data\n",
    "- Flatten the image data into 1-D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421b96a",
   "metadata": {
    "id": "a82e79ad"
   },
   "outputs": [],
   "source": [
    "# Import 'numpy' and 'pandas' to work with numbers and dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import 'pyplot' from 'matplotlib' and 'seaborn' for visualizations\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import methods for building neural networks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Import 'GridSearchCV' for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import 'KerasClassifier' from 'keras' for connecting neural networks with 'sklearn' and 'GridSearchCV'\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Import method to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09f763",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "a251d675",
    "outputId": "80cb8cc4-9d84-459c-a381-5ecf6d003770"
   },
   "outputs": [],
   "source": [
    "# Install the EMNIST package\n",
    "# Note: If you haven't already installed the EMNIST package, run the following code to do so\n",
    "# !pip install emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'letters' data (training and testing) from 'emnist'\n",
    "# Note: The EMNIST data size is about 536 MB, so the download may take a couple of minutes\n",
    "from emnist import extract_training_samples, extract_test_samples\n",
    "X_train, y_train = extract_training_samples('letters')\n",
    "X_test, y_test = extract_test_samples('letters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360727fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train data shape: ', X_train.shape) # (124800, 28, 28) --- 124800 images, each 28x28 pixels\n",
    "print('Test data shape: ', X_test.shape) # (20800, 28, 28) --- 20800 images, each 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bead67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the frequency of the unique class labels in the training data\n",
    "unique, counts = np.unique(y_train, return_counts = True)\n",
    "print('Train labels: ', dict(zip(unique, counts)))\n",
    "\n",
    "# Look at the frequency of the unique class labels in the testing data\n",
    "unique, counts = np.unique(y_test, return_counts = True)\n",
    "print('Test labels: ', dict(zip(unique, counts)))\n",
    "\n",
    "print('\\n')\n",
    "print('Note that the labels 1, 2, 3, ..., 26 represent the 26 letters of the English alphabet.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61176eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 25 EMNIST images from the training data and view the images\n",
    "indices = np.random.randint(0, X_train.shape[0], size = 25)\n",
    "\n",
    "images = X_train[indices]\n",
    "labels = y_train[indices]\n",
    "\n",
    "plt.figure(figsize = (5, 5))\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    image = images[i]\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pixel gray level values from the range [0, 255] to the range [0,1]\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a few training data images and their corresponding labels\n",
    "indices = np.random.randint(0, X_train.shape[0], size = 10)\n",
    "plt.figure(figsize = (16, 8))\n",
    "\n",
    "indexcount = 0\n",
    "for data_index in indices:\n",
    "    indexcount = indexcount + 1\n",
    "    plt.subplot(1, 10, indexcount)\n",
    "    plt.imshow(X_train[data_index], cmap = 'gray')\n",
    "    plt.title(str(y_train[data_index]))\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075857c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a few testing data images and their corresponding labels\n",
    "indices = np.random.randint(0, X_test.shape[0], size = 10)\n",
    "plt.figure(figsize = (16, 8))\n",
    "\n",
    "indexcount = 0\n",
    "for data_index in indices:\n",
    "    indexcount = indexcount + 1\n",
    "    plt.subplot(1, 10, indexcount)\n",
    "    plt.imshow(X_test[data_index], cmap = 'gray')\n",
    "    plt.title(str(y_test[data_index]))\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316270d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the class labels to one-hot encoded vectors using the 'to_categorical()' function\n",
    "num_classes = 26\n",
    "\n",
    "# Note: Reduce all y labels by 1 to ensure that labeling starts at 0 and ends at 25\n",
    "y_train = to_categorical(y_train - 1, num_classes)\n",
    "y_test = to_categorical(y_test - 1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a couple of training data images and their corresponding labels\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "for data_index in np.arange(0, 2, 1):\n",
    "    plt.subplot(1, 2, data_index + 1)\n",
    "    plt.imshow(X_train[data_index], cmap = 'gray')\n",
    "    plt.title(str(y_train[data_index]))\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a03cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a couple of testing data images and their corresponding labels\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "for data_index in np.arange(0, 2, 1):\n",
    "    plt.subplot(1, 2, data_index + 1)\n",
    "    plt.imshow(X_test[data_index], cmap = 'gray')\n",
    "    plt.title(str(y_test[data_index]))\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images by converting them into a list of values\n",
    "image_vector_size = 28 * 28\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], image_vector_size)\n",
    "X_test = X_test.reshape(X_test.shape[0], image_vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a135f",
   "metadata": {
    "id": "e359ec34"
   },
   "source": [
    "# Task 2 - FCFNN\n",
    "For this task, you will perform the following steps:\n",
    "- Build a simple neural network (1 hidden layer and 2 neurons in the hidden layer) using *keras* and train it on the training data\n",
    "- Check its performance on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf62e1d",
   "metadata": {
    "id": "6a328625",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a neural network with 1 hidden layer and 2 neurons in the hidden layer and train it on the training data\n",
    "\n",
    "# Declare an instance of an artificial neural network model using the 'Sequential()' method\n",
    "nn1 = Sequential()\n",
    "\n",
    "# Add the first hidden layer using the 'add()' and 'Dense()' methods\n",
    "# Note: Set the 'units' parameter to 2 - This specifies the number of neurons in the hidden layer\n",
    "# Note: Set the 'input_shape' parameter to (image_vector_size, ) - This specifies the number of input features for each record\n",
    "# Note: Set the 'activation' parameter to 'sigmoid' - This specifies the type of activation function to use for the neurons in this layer\n",
    "nn1.add(Dense(units = 2,\n",
    "              input_shape = (image_vector_size, ),\n",
    "              activation = 'sigmoid'))\n",
    "\n",
    "# Add the output layer using the 'add()' and 'Dense()' methods\n",
    "# Note: Set the 'units' parameter to 'num_classes' - Multiclass classification with 26 classes requires 26 output neurons\n",
    "# Note: Set the 'activation' parameter to 'softmax' - The softmax activation function is commonly used for output layer neurons in multiclass classification tasks\n",
    "nn1.add(Dense(units = num_classes,\n",
    "              activation = 'softmax'))\n",
    "\n",
    "# Compile the model using the 'compile()' method\n",
    "# Note: Set the 'loss' parameter to 'categorical_crossentropy' - The categorical crossentropy loss function is commonly used for multiclass classification tasks\n",
    "# Note: Set the 'metrics' parameter to 'accuracy' - This records the accuracy of the model along with the loss during training\n",
    "nn1.compile(loss = 'categorical_crossentropy',\n",
    "            metrics = 'accuracy')\n",
    "\n",
    "# Train the model on the training data using the 'fit()' method\n",
    "# Note: Set the 'validation_split' parameter to 0.2 - This sets aside 20% of the training data as validation data\n",
    "# Note: Set the 'epochs' parameter to 200 - This specifies the scope of loss computations and parameter updates\n",
    "# Note: Set the 'batch_size' to 'X_train.shape[0]' - This specifies the batch size as the complete training data set instead of the default value of 32\n",
    "nn1.summary()\n",
    "print('\\n')\n",
    "nn1.fit(X_train, y_train, batch_size = X_train.shape[0], validation_split = 0.2, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014660d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrain the model and this time, save its training history\n",
    "\n",
    "# Declare an instance of an artificial neural network model using the 'Sequential()' method\n",
    "nn1 = Sequential()\n",
    "\n",
    "# Add the first hidden layer using the 'add()' and 'Dense()' methods\n",
    "# Note: Set the 'units' parameter to 2\n",
    "# Note: Set the 'input_shape' parameter to (image_vector_size, )\n",
    "# Note: Set the 'activation' parameter to 'sigmoid'\n",
    "nn1.add(Dense(units = 2,\n",
    "              input_shape = (image_vector_size, ),\n",
    "              activation = 'sigmoid'))\n",
    "\n",
    "# Add the output layer using the 'add()' and 'Dense()' methods\n",
    "# Note: Set the 'units' parameter to 'num_classes'\n",
    "# Note: Set the 'activation' parameter to 'softmax'\n",
    "nn1.add(Dense(units = num_classes,\n",
    "              activation = 'softmax'))\n",
    "\n",
    "# Compile the model using the 'compile()' method\n",
    "# Note: Set the 'loss' parameter to 'categorical_crossentropy'\n",
    "# Note: Set the 'metrics' parameter to 'accuracy'\n",
    "nn1.compile(loss = 'categorical_crossentropy',\n",
    "            metrics = 'accuracy')\n",
    "\n",
    "# Capture the training history of the model using the 'fit()' method\n",
    "# Note: Set the 'validation_split' parameter to 0.2\n",
    "# Note: Set the 'epochs' parameter to 200\n",
    "# Note: Set the 'batch_size' to 'X_train.shape[0]'\n",
    "nn1.summary()\n",
    "print('\\n')\n",
    "nn1_history = nn1.fit(X_train, y_train, batch_size = X_train.shape[0], validation_split = 0.2, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73705c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the neural network history object into a data frame to view its specifics\n",
    "hist = pd.DataFrame(nn1_history.history)\n",
    "hist['epoch'] = nn1_history.epoch\n",
    "hist['epoch'] = hist['epoch'].apply(lambda x: x + 1)\n",
    "hist.set_index('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the training and validation accuracies as functions of epoch\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'accuracy', color = 'red', label = 'Training')\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'val_accuracy', color = 'blue', label = 'Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy as a Function of Epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2820d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model on the testing data set using the 'evaluate()' method\n",
    "performance_test = nn1.evaluate(X_test, y_test)\n",
    "\n",
    "print('The loss value of the model on the test data is {}'.format(performance_test[0]))\n",
    "print('The accuracy of the model on the test data is {}'.format(performance_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c2c254",
   "metadata": {},
   "source": [
    "# Task 3 - FCFNN Hyperparameter Tuning: Number of Neurons\n",
    "For this task, you will perform the following steps:\n",
    "- Build a neural network (1 hidden layer and tuned for number of neurons) using *keras* and train it on the training data\n",
    "- View the impact of number of neurons on the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27457b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Declare a range of number of neurons per hidden layer to tune for\n",
    "n_neurons_list = [2, 8, 32, 128]\n",
    "\n",
    "# Create and train a neural network model for each value of number of neurons per hidden layer\n",
    "performance_df = pd.DataFrame(data = None)\n",
    "hist = [None] * 4\n",
    "indexcount = -1\n",
    "\n",
    "for n_neu in n_neurons_list:\n",
    "    indexcount = indexcount + 1\n",
    "    \n",
    "    # Declare an instance of an artificial neural network model using the 'Sequential()' method\n",
    "    nn = Sequential()\n",
    "    \n",
    "    # Add the first hidden layer using the 'add()' and 'Dense()' methods\n",
    "    # Note: Set the 'units' parameter to 'n_neu' - This specifies the current number of neurons per hidden layer\n",
    "    # Note: Set the 'input_shape' parameter to (image_vector_size, )\n",
    "    # Note: Set the 'activation' parameter to 'sigmoid'\n",
    "    nn.add(Dense(units = n_neu,\n",
    "                 input_shape = (image_vector_size, ),\n",
    "                 activation = 'sigmoid'))\n",
    "    \n",
    "    # Add the output layer using the 'add()' and 'Dense()' methods\n",
    "    # Note: Set the 'units' parameter to 'num_classes'\n",
    "    # Note: Set the 'activation' parameter to 'softmax'\n",
    "    nn.add(Dense(units = num_classes,\n",
    "                 activation = 'softmax'))\n",
    "    \n",
    "    # Compile the model using the 'compile()' method\n",
    "    # Note: Set the 'loss' parameter to 'categorical_crossentropy'\n",
    "    # Note: Set the 'metrics' parameter to 'accuracy'\n",
    "    nn.compile(loss = 'categorical_crossentropy',\n",
    "               metrics = 'accuracy')\n",
    "    \n",
    "    # Capture the training history of the model using the 'fit()' method\n",
    "    # Note: Set the 'validation_split' parameter to 0.2\n",
    "    # Note: Set the 'epochs' parameter to 200\n",
    "    # Note: Set the 'batch_size' to 'X_train.shape[0]'\n",
    "    print('\\n Training and validation for {} neurons - START \\n'.format(n_neu))\n",
    "    nn.summary()\n",
    "    print('\\n')\n",
    "    nn_history = nn.fit(X_train, y_train, batch_size = X_train.shape[0], validation_split = 0.2, epochs = 200)\n",
    "    print('\\n Training and validation for {} neurons - END \\n'.format(n_neu))\n",
    "    \n",
    "    hist[indexcount] = pd.DataFrame(nn_history.history)\n",
    "    hist[indexcount]['epoch'] = nn_history.epoch\n",
    "    \n",
    "    tempdf = pd.DataFrame(index = [indexcount],\n",
    "                          data = {'Number of Neurons': n_neu,\n",
    "                                  'Train Accuracy': hist[indexcount]['accuracy'][199],\n",
    "                                  'Validation Accuracy': hist[indexcount]['val_accuracy'][199]})\n",
    "    \n",
    "    performance_df = pd.concat([performance_df, tempdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b79fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the training and validation accuracies as functions of number of neurons\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "sns.lineplot(data = performance_df, x = 'Number of Neurons', y = 'Train Accuracy', color = 'red', label = 'Training')\n",
    "sns.lineplot(data = performance_df, x = 'Number of Neurons', y = 'Validation Accuracy', color = 'blue', label = 'Validation')\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy as a Function of Number of Neurons');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the training accuracies as functions of epochs for different values of number of neurons\n",
    "plt.figure(figsize = (14, 4))\n",
    "colorlist = ['purple', 'green', 'blue', 'red']\n",
    "\n",
    "indexcount = -1\n",
    "for n_neu in n_neurons_list:\n",
    "    indexcount = indexcount + 1\n",
    "    sns.lineplot(data = hist[indexcount],\n",
    "                 x = 'epoch',\n",
    "                 y = 'accuracy',\n",
    "                 color = colorlist[indexcount],\n",
    "                 label = str(n_neu) + ' neurons')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy as a Function of Epoch for Different Values of Number of Neurons');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2190dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the validation accuracies as functions of epochs for different values of number of neurons\n",
    "plt.figure(figsize = (14, 4))\n",
    "colorlist = ['purple', 'green', 'blue', 'red']\n",
    "\n",
    "indexcount = -1\n",
    "for n_neu in n_neurons_list:\n",
    "    indexcount = indexcount + 1\n",
    "    sns.lineplot(data = hist[indexcount],\n",
    "                 x = 'epoch',\n",
    "                 y = 'val_accuracy',\n",
    "                 color = colorlist[indexcount],\n",
    "                 label = str(n_neu) + ' neurons')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy as a Function of Epoch for Different Values of Number of Neurons');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e6f89",
   "metadata": {},
   "source": [
    "# Task 4 - FCFNN Hyperparameter Tuning: Number of Hidden Layers\n",
    "For this task, you will perform the following steps:\n",
    "- Build a neural network (2 neurons per hidden layer and tuned for the number of hidden layers) using *keras* and train it on the training data\n",
    "- View the impact of number of hidden layers on the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4a23d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Declare a range of number of hidden layers to tune for\n",
    "n_hidden_list = [1, 2, 3, 4]\n",
    "\n",
    "# Create and train a neural network model for each value of number of hidden layers\n",
    "performance_df = pd.DataFrame(data = None)\n",
    "hist = [None] * 4\n",
    "indexcount = -1\n",
    "\n",
    "for n_hid in n_hidden_list:\n",
    "    indexcount = indexcount + 1\n",
    "    \n",
    "    # Declare an instance of an artificial neural network model using the 'Sequential()' method\n",
    "    nn = Sequential()\n",
    "    \n",
    "    # Add the first hidden layer using the 'add()' and 'Dense()' methods\n",
    "    # Note: Set the 'units' parameter to 2\n",
    "    # Note: Set the 'input_shape' parameter to (image_vector_size, )\n",
    "    # Note: Set the 'activation' parameter to 'sigmoid'\n",
    "    nn.add(Dense(units = 2,\n",
    "                 input_shape = (image_vector_size, ),\n",
    "                 activation = 'sigmoid'))\n",
    "    \n",
    "    # Conditionally add the remaining hidden layers using the 'add()' and 'Dense()' methods and a 'for' loop\n",
    "    # Note: Set the 'units' parameter to 2\n",
    "    # Note: Set the 'activation' parameter to 'sigmoid'\n",
    "    # Note: The 'input_shape' parameter is derived from the previous layer automatically\n",
    "    for temp_n_hid in np.arange(1, n_hid, 1):\n",
    "        nn.add(Dense(units = 2,\n",
    "                     activation = 'sigmoid'))\n",
    "    \n",
    "    # Add the output layer using the 'add()' and 'Dense()' methods\n",
    "    # Note: Set the 'units' parameter to 'num_classes'\n",
    "    # Note: Set the 'activation' parameter to 'softmax'\n",
    "    nn.add(Dense(units = num_classes,\n",
    "                 activation = 'softmax'))\n",
    "    \n",
    "    # Compile the model using the 'compile()' method\n",
    "    # Note: Set the 'loss' parameter to 'categorical_crossentropy'\n",
    "    # Note: Set the 'metrics' parameter to 'accuracy'\n",
    "    nn.compile(loss = 'categorical_crossentropy',\n",
    "               metrics = 'accuracy')\n",
    "    \n",
    "    # Capture the training history of the model using the 'fit()' method\n",
    "    # Note: Set the 'validation_split' parameter to 0.2\n",
    "    # Note: Set the 'epochs' parameter to 200\n",
    "    # Note: Set the 'batch_size' to 'X_train.shape[0]'\n",
    "    print('\\n Training and validation for {} hidden layers - START \\n'.format(n_hid))\n",
    "    nn.summary()\n",
    "    print('\\n')\n",
    "    nn_history = nn.fit(X_train, y_train, batch_size = X_train.shape[0], validation_split = 0.2, epochs = 200)\n",
    "    print('\\n Training and validation for {} hidden layers - END \\n'.format(n_hid))\n",
    "    \n",
    "    hist[indexcount] = pd.DataFrame(nn_history.history)\n",
    "    hist[indexcount]['epoch'] = nn_history.epoch\n",
    "    \n",
    "    tempdf = pd.DataFrame(index = [indexcount],\n",
    "                          data = {'Number of Hidden Layers': n_hid,\n",
    "                                  'Train Accuracy': hist[indexcount]['accuracy'][199],\n",
    "                                  'Validation Accuracy': hist[indexcount]['val_accuracy'][199]})\n",
    "    \n",
    "    performance_df = pd.concat([performance_df, tempdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbef651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the training and validation accuracies as functions of number of hidden layers\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "sns.lineplot(data = performance_df, x = 'Number of Hidden Layers', y = 'Train Accuracy', color = 'red', label = 'Training')\n",
    "sns.lineplot(data = performance_df, x = 'Number of Hidden Layers', y = 'Validation Accuracy', color = 'blue', label = 'Validation')\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy as a Function of Number of Hidden Layers');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the training accuracies as functions of epochs for different values of number of hidden layers\n",
    "plt.figure(figsize = (14, 4))\n",
    "colorlist = ['purple', 'green', 'blue', 'red']\n",
    "\n",
    "indexcount = -1\n",
    "for n_hid in n_hidden_list:\n",
    "    indexcount = indexcount + 1\n",
    "    if n_hid == 1:\n",
    "        currentlabel = '1 hidden layer'\n",
    "    else:\n",
    "        currentlabel = str(n_hid) + ' hidden layers'\n",
    "    sns.lineplot(data = hist[indexcount],\n",
    "                 x = 'epoch',\n",
    "                 y = 'accuracy',\n",
    "                 color = colorlist[indexcount],\n",
    "                 label = currentlabel)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy as a Function of Epoch for Different Values of Number of Hidden Layers');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the validation accuracies as functions of epochs for different values of number of hidden layers\n",
    "plt.figure(figsize = (14, 4))\n",
    "colorlist = ['purple', 'green', 'blue', 'red']\n",
    "\n",
    "indexcount = -1\n",
    "for n_hid in n_hidden_list:\n",
    "    indexcount = indexcount + 1\n",
    "    if n_hid == 1:\n",
    "        currentlabel = '1 hidden layer'\n",
    "    else:\n",
    "        currentlabel = str(n_hid) + ' hidden layers'\n",
    "    sns.lineplot(data = hist[indexcount],\n",
    "                 x = 'epoch',\n",
    "                 y = 'val_accuracy',\n",
    "                 color = colorlist[indexcount],\n",
    "                 label = currentlabel)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy as a Function of Epoch for Different Values of Number of Hidden Layers');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6199df",
   "metadata": {},
   "source": [
    "# Task 5 - FCFNN Hyperparameter Tuning: Combinations of Hyperparameters\n",
    "For this task, you will perform the following steps:\n",
    "- Build a neural network (tuned for both the number of hidden layers and the number of neurons per hidden layer) using *keras* and train it on the training data\n",
    "- Test its performance on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a neural network model\n",
    "# Note: Declare the number of hidden layers and the number of neurons per hidden layer as variable parameters of the function\n",
    "def create_nn(n_hidden = 1, n_neurons = 2):\n",
    "    \n",
    "    # Declare an instance of an artificial neural network model using the 'Sequential()' method\n",
    "    nn = Sequential()\n",
    "    \n",
    "    # Add the first hidden layer using the 'add()' and 'Dense()' methods\n",
    "    # Note: Set the 'units' parameter to 'n_neurons' - This specifies the selected number of neurons per hidden layer\n",
    "    # Note: Set the 'input_shape' parameter to (image_vector_size, )\n",
    "    # Note: Set the 'activation' parameter to 'sigmoid'\n",
    "    nn.add(Dense(units = n_neurons,\n",
    "                 input_shape = (image_vector_size, ),\n",
    "                 activation = 'sigmoid'))\n",
    "    \n",
    "    # Conditionally add the remaining hidden layers using the 'add()' and 'Dense()' methods and a 'for' loop\n",
    "    # Note: Set the 'units' parameter to 'n_neurons' - This specifies the selected number of neurons per hidden layer\n",
    "    # Note: Set the 'activation' parameter to 'sigmoid'\n",
    "    # Note: The 'input_shape' parameter is derived from the previous layer automatically\n",
    "    for n_hid in np.arange(1, n_hidden, 1):\n",
    "        nn.add(Dense(units = n_neurons,\n",
    "                     activation = 'sigmoid'))\n",
    "    \n",
    "    # Add the output layer using the 'add()' and 'Dense()' methods\n",
    "    # Note: Set the 'units' parameter to 'num_classes'\n",
    "    # Note: Set the 'activation' parameter to 'softmax'\n",
    "    nn.add(Dense(units = num_classes,\n",
    "                 activation = 'softmax'))\n",
    "    \n",
    "    # Compile the model using the 'compile()' method\n",
    "    # Note: Set the 'loss' parameter to 'categorical_crossentropy'\n",
    "    # Note: Set the 'metrics' parameter to 'accuracy'\n",
    "    nn.compile(loss = 'categorical_crossentropy',\n",
    "               metrics = 'accuracy')\n",
    "    \n",
    "    return(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe6c19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a basic neural network object using the 'KerasClassifier()' method\n",
    "# Note: Set the 'build_fn' parameter to 'create_nn' - This converts the 'create_nn' function into a 'KerasClassifier' object\n",
    "base_grid_model = KerasClassifier(build_fn = create_nn)\n",
    "\n",
    "# Define the range of the 'n_hidden' and 'n_neurons' parameters and store it in a parameter grid dictionary\n",
    "parameters_grid = {'n_hidden': [1, 2], 'n_neurons': [32, 128]}\n",
    "\n",
    "# Perform a grid search using the 'GridSearchCV()' method to obtain a grid on which to fit the training data\n",
    "# Note: Set the 'estimator' parameter to 'base_grid_model' - This specifies the estimator to be used by 'GridSearchCV()'\n",
    "# Note: Set the 'param_grid' parameter to 'parameters_grid' - This specifies the grid of parameters to search over\n",
    "# Note: Set the 'cv' parameter to 2 - This specifies the number of folds in the cross-validation process\n",
    "# Note: Set the 'verbose' parameter to 4 - This helps show more relevant information during training\n",
    "grid = GridSearchCV(estimator = base_grid_model,\n",
    "                    param_grid = parameters_grid,\n",
    "                    cv = 2,\n",
    "                    verbose = 4)\n",
    "\n",
    "# Train the model on the training data using the 'fit()' method\n",
    "# Note: Set the 'epochs' parameter to 200\n",
    "# Note: Set the 'batch_size' to 'X_train.shape[0]'\n",
    "# Note: The 'validation_split' parameter isn't particularly required since cross-validation is already in place\n",
    "grid_model = grid.fit(X_train, y_train, batch_size = X_train.shape[0], epochs = 200)\n",
    "\n",
    "# Print the optimal values of 'n_hidden' and 'n_neurons'\n",
    "best_n_hidden = grid_model.best_params_['n_hidden']\n",
    "best_n_neurons = grid_model.best_params_['n_neurons']\n",
    "best_accuracy = grid_model.best_score_\n",
    "\n",
    "print('The optimal value of number of hidden layers is', best_n_hidden)\n",
    "print('The optimal value of number of neurons per hidden layer is', best_n_neurons)\n",
    "print('The accuracy of the model with these optimal parameters is ', best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838332c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrain the model with the optimal combination of hyperparameters and save its training history\n",
    "\n",
    "# Use the 'create_nn' function to create a neural network with the optimal values of 'n_hidden' and 'n_neurons'\n",
    "# Note: Set the 'n_hidden' parameter to 'best_n_hidden' - This specifies the optimal value for the 'n_hidden' parameter\n",
    "# Note: Set the 'n_neurons' parameter to 'best_n_neurons' - This specifies the optimal value for the 'n_neurons' parameter\n",
    "nn2 = create_nn(n_hidden = best_n_hidden, n_neurons = best_n_neurons)\n",
    "\n",
    "# Capture the training history of the model using the 'fit()' method\n",
    "# Note: Set the 'validation_split' parameter to 0.2\n",
    "# Note: Set the 'epochs' parameter to 200\n",
    "# Note: Set the 'batch_size' to 'X_train.shape[0]'\n",
    "nn2.summary()\n",
    "print('\\n')\n",
    "nn2_history = nn2.fit(X_train, y_train, batch_size = X_train.shape[0], validation_split = 0.2, epochs = 200)\n",
    "hist = pd.DataFrame(nn2_history.history)\n",
    "hist['epoch'] = nn2_history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the training and validation accuracies as functions of epoch\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'accuracy', color = 'red', label = 'Training')\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'val_accuracy', color = 'blue', label = 'Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy as a Function of Epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model on the testing data set using the 'evaluate()' method\n",
    "performance_test = nn2.evaluate(X_test, y_test)\n",
    "\n",
    "print('The loss value of the model on the test data is {}'.format(performance_test[0]))\n",
    "print('The accuracy of the model on the test data is {}'.format(performance_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fadddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C3M4_v4b.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
