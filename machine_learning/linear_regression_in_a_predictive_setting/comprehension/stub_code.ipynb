{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**------------------------------------------------------------------------------------------------------------------------**\n",
    "# Model Building\n",
    "**------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "house = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house.drop([\"Id\", \"SalePrice\", \"TransformedPrice\"], axis=1).values\n",
    "y = house[\"TransformedPrice\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of alphas to tune\n",
    "alphas= [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0, 20, 50, 100, 1000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant libraries\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "def rmse(y_train, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Linear Model\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Ordinary least squares Linear Regression.\n",
       "\n",
       "LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
       "to minimize the residual sum of squares between the observed targets in\n",
       "the dataset, and the targets predicted by the linear approximation.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "fit_intercept : bool, default=True\n",
       "    Whether to calculate the intercept for this model. If set\n",
       "    to False, no intercept will be used in calculations\n",
       "    (i.e. data is expected to be centered).\n",
       "\n",
       "copy_X : bool, default=True\n",
       "    If True, X will be copied; else, it may be overwritten.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to use for the computation. This will only provide\n",
       "    speedup in case of sufficiently large problems, that is if firstly\n",
       "    `n_targets > 1` and secondly `X` is sparse or if `positive` is set\n",
       "    to `True`. ``None`` means 1 unless in a\n",
       "    :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
       "    processors. See :term:`Glossary <n_jobs>` for more details.\n",
       "\n",
       "positive : bool, default=False\n",
       "    When set to ``True``, forces the coefficients to be positive. This\n",
       "    option is only supported for dense arrays.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
       "    Estimated coefficients for the linear regression problem.\n",
       "    If multiple targets are passed during the fit (y 2D), this\n",
       "    is a 2D array of shape (n_targets, n_features), while if only\n",
       "    one target is passed, this is a 1D array of length n_features.\n",
       "\n",
       "rank_ : int\n",
       "    Rank of matrix `X`. Only available when `X` is dense.\n",
       "\n",
       "singular_ : array of shape (min(X, y),)\n",
       "    Singular values of `X`. Only available when `X` is dense.\n",
       "\n",
       "intercept_ : float or array of shape (n_targets,)\n",
       "    Independent term in the linear model. Set to 0.0 if\n",
       "    `fit_intercept = False`.\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Ridge : Ridge regression addresses some of the\n",
       "    problems of Ordinary Least Squares by imposing a penalty on the\n",
       "    size of the coefficients with l2 regularization.\n",
       "Lasso : The Lasso is a linear model that estimates\n",
       "    sparse coefficients with l1 regularization.\n",
       "ElasticNet : Elastic-Net is a linear regression\n",
       "    model trained with both l1 and l2 -norm regularization of the\n",
       "    coefficients.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "From the implementation point of view, this is just plain Ordinary\n",
       "Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
       "(scipy.optimize.nnls) wrapped as a predictor object.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.linear_model import LinearRegression\n",
       ">>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
       ">>> # y = 1 * x_0 + 2 * x_1 + 3\n",
       ">>> y = np.dot(X, np.array([1, 2])) + 3\n",
       ">>> reg = LinearRegression().fit(X, y)\n",
       ">>> reg.score(X, y)\n",
       "1.0\n",
       ">>> reg.coef_\n",
       "array([1., 2.])\n",
       ">>> reg.intercept_\n",
       "3.0...\n",
       ">>> reg.predict(np.array([[3, 5]]))\n",
       "array([16.])\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\vr3n\\codes\\upgrad-maryland-analytics\\upgrad_venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the linear regression model here\n",
    "lr = LinearRegression()\n",
    "lr = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 0.1199\n",
      "RMSE on test: 0.184\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on train:\",round(rmse(y_train,lr.predict(X_train)),4))\n",
    "print(\"RMSE on test:\",round(rmse(y_test,lr.predict(X_test)),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lasso\n",
    "---\n",
    "1. Run Lasso with alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Lasso regression with alpha = 1\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso = lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 0.4\n",
      "RMSE on test: 0.399\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on train:\",round(rmse(y_train,lasso.predict(X_train)),3))\n",
    "print(\"RMSE on test:\",round(rmse(y_test,lasso.predict(X_test)),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LassoCV \n",
    "2. Run LassoCV and find best alpha value (from the list of alphas given earlier)\n",
    "3. In the best model, find % of features that are eliminated\n",
    "4. RMSE for the best Lasso model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas= [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0, 20, 50, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha is: 0.001\n"
     ]
    }
   ],
   "source": [
    "#Train LassoCV for alphas and find best alpha\n",
    "lassocv = LassoCV(alphas=alphas, cv=5)\n",
    "lassocv = lassocv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best alpha is: {lassocv.alpha_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of coefficients turning 0: 15.38%\n"
     ]
    }
   ],
   "source": [
    "#Find the percentage of coefficients turning 0\n",
    "zero_coefficients_percentage = np.sum(lassocv.coef_ == 0) / len(lassocv.coef_) * 100\n",
    "print(f\"Percentage of coefficients turning 0: {zero_coefficients_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 0.1203\n",
      "RMSE on test: 0.1824\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on train:\",round(rmse(y_train,lassocv.predict(X_train)),4))\n",
    "print(\"RMSE on test:\",round(rmse(y_test,lassocv.predict(X_test)),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.909\n",
      "Test score: 0.791\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score:\",round(lassocv.score(X_train,y_train),3))\n",
    "print(\"Test score:\",round(lassocv.score(X_test,y_test),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best LASSO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Lasso regression with alpha = 1\n",
    "lasso_best = Lasso(alpha=lassocv.alpha_)\n",
    "lasso_best = lasso_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 0.1203\n",
      "RMSE on test: 0.1824\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on train:\",round(rmse(y_train,lasso_best.predict(X_train)),4))\n",
    "print(\"RMSE on test:\",round(rmse(y_test,lasso_best.predict(X_test)),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ridge\n",
    "---\n",
    "1. Run Ridge with alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Ridge regression for alpha = 1\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge = ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 0.12\n",
      "RMSE on test: 0.184\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on train:\",round(rmse(y_train,ridge.predict(X_train)),3))\n",
    "print(\"RMSE on test:\",round(rmse(y_test,ridge.predict(X_test)),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha is: 100.0\n"
     ]
    }
   ],
   "source": [
    "#Train RidgeCV for alphas and find best alpha\n",
    "ridgecv = RidgeCV(alphas=alphas, cv=5)\n",
    "ridgecv = ridgecv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best alpha is: {ridgecv.alpha_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The % difference in the first coefficient between linear regression and Ridge model is: 39.58090868257646\n"
     ]
    }
   ],
   "source": [
    "#Find the % difference in the first coefficient between linear regression and Ridge model\n",
    "# Get the coefficients from both models\n",
    "coeff_linear = lr.coef_[0]\n",
    "coeff_ridge = ridgecv.coef_[0]\n",
    "\n",
    "# Calculate the percentage difference\n",
    "percentage_difference = ((coeff_ridge - coeff_linear) / np.abs(coeff_linear)) * 100\n",
    "\n",
    "print(f\"The % difference in the first coefficient between linear regression and Ridge model is: {percentage_difference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 0.121\n",
      "RMSE on test: 0.1817\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on train:\",round(rmse(y_train,ridgecv.predict(X_train)),4))\n",
    "print(\"RMSE on test:\",round(rmse(y_test,ridgecv.predict(X_test)),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.908\n",
      "Test score: 0.793\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score:\",round(ridgecv.score(X_train,y_train),3))\n",
    "print(\"Test score:\",round(ridgecv.score(X_test,y_test),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Ridge regression for alpha = 1\n",
    "ridge_best = Ridge(alpha=ridgecv.alpha_)\n",
    "ridge_best = ridge_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 0.121\n",
      "RMSE on test: 0.1817\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on train:\",round(rmse(y_train,ridge_best.predict(X_train)),4))\n",
    "print(\"RMSE on test:\",round(rmse(y_test,ridge_best.predict(X_test)),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
