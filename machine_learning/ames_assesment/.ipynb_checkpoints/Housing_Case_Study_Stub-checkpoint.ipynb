{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hDX3GkJRLRY2",
   "metadata": {
    "id": "hDX3GkJRLRY2"
   },
   "source": [
    "### Problem Statement\n",
    "\n",
    "*Predicting housing prices is of interest to potential buyers, sellers, and organizations alike. Multiple online platforms offer, for example, a free “price estimate” based on underlying machine learning models. For this assignment, we are going to build the best machine learning model we can for Ames, Iowa. The data set consists of 79 features that describe the quality and quantity of the properties to base our predictions on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e29495",
   "metadata": {
    "id": "59e29495"
   },
   "source": [
    "# Task 0: Data Preperation\n",
    "\n",
    "*Note: No code has to be written for the 5 cells below - you may just execute them sequentially. After this, you may move on to **Task 1** on understanding the data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b87c95",
   "metadata": {
    "id": "42b87c95"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e422c0",
   "metadata": {
    "id": "18e422c0"
   },
   "outputs": [],
   "source": [
    "# All missing data removed/cleaned\n",
    "housing_df = pd.read_csv(\"ames_data_no_missing.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5c4ad",
   "metadata": {
    "id": "29b5c4ad"
   },
   "outputs": [],
   "source": [
    "#Check the number of dummies to be created\n",
    "count = [housing_df[col].nunique() for col in housing_df.columns if housing_df[col].dtype==object]\n",
    "sum(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a6082",
   "metadata": {
    "id": "4c3a6082"
   },
   "outputs": [],
   "source": [
    "# ensure Python reads the categorical variables as categorical\n",
    "for column in housing_df.columns:\n",
    "    if housing_df[column].dtype == 'object':\n",
    "        housing_df[column] = pd.Categorical(housing_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df2b78f",
   "metadata": {
    "id": "2df2b78f"
   },
   "outputs": [],
   "source": [
    "#define our RMSE function\n",
    "def rmse(y_train, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91c10f",
   "metadata": {
    "id": "fd91c10f"
   },
   "source": [
    "# Task 1: Understand the Data\n",
    "*Take some time to familiarize yourself with the data. It contains information about housing prices in Ames. What are the key variables?*\n",
    "\n",
    "*You may perform any additional EDA if necessary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6227ca",
   "metadata": {
    "id": "ec6227ca"
   },
   "source": [
    "### 1.1\n",
    "*What is the distribution of housing prices?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51547a8",
   "metadata": {
    "id": "b51547a8"
   },
   "outputs": [],
   "source": [
    "# The original distribution\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560316fd",
   "metadata": {
    "id": "560316fd"
   },
   "source": [
    "### 1.2\n",
    "*What is the variable that has the highest correlation with Housing prices? What are the key drivers behind larger house prices?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GSxPyBkt1QgZ",
   "metadata": {
    "id": "GSxPyBkt1QgZ"
   },
   "outputs": [],
   "source": [
    "#Find the correlations of all variables with SalePrice\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tnBw_QHBOZax",
   "metadata": {
    "id": "tnBw_QHBOZax"
   },
   "source": [
    "### 1.3\n",
    "*Create one additional visualization, that gives some insights into the data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360aa273",
   "metadata": {
    "id": "360aa273"
   },
   "outputs": [],
   "source": [
    "# Create a visualization to highlight any insight - Can be a scatter plot, line plot, box plot, histogram or any other visualization that you might know!\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665cd34a",
   "metadata": {
    "id": "665cd34a"
   },
   "source": [
    "# Task 2: Build machine learning models\n",
    "\n",
    "*Use your knowledge of prediction models to create at least three models that predict housing prices.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069db182",
   "metadata": {
    "id": "069db182"
   },
   "source": [
    "### 2.1 \n",
    "1. *Create dummies for all the categorical columns*.\n",
    "\n",
    "2. *Partition your data into training and validation (70-30 split, setting the random state to 1).*\n",
    "3. *Scale the train and the test set using StandardScaler()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738deae",
   "metadata": {
    "id": "c738deae"
   },
   "outputs": [],
   "source": [
    "# Initialize X and y\n",
    "X = housing_df.drop(columns=['SalePrice']) # All but the outcome column\n",
    "y = housing_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UxSr_jB6lgUZ",
   "metadata": {
    "id": "UxSr_jB6lgUZ"
   },
   "outputs": [],
   "source": [
    "# Use dummy variables for categorical variables\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oLRB24jAlgN2",
   "metadata": {
    "id": "oLRB24jAlgN2"
   },
   "outputs": [],
   "source": [
    "# Train - Test split (70-30 split, setting the random state to 1)\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4POCJmKclgD3",
   "metadata": {
    "id": "4POCJmKclgD3"
   },
   "outputs": [],
   "source": [
    "# Scale the train and test set features separately\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = [col for col in X.columns if X[col].dtypes != 'category']\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db9fd0",
   "metadata": {
    "id": "c2db9fd0"
   },
   "source": [
    "### 2.2\n",
    "*Build a linear regression model, a regression tree and a kNN model. Carefully apply regularization for the linear regression model. Carefully select which variables to use for the kNN model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa0a04",
   "metadata": {
    "id": "4bfa0a04"
   },
   "outputs": [],
   "source": [
    "# Linear model - USE LassoCV to get the best LASSO model\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb3683",
   "metadata": {
    "id": "b5cb3683"
   },
   "outputs": [],
   "source": [
    "# Tree Model - Use max depth to control the complexity of the tree. Run a Grid search for multiple values of max depth.\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79ce2d",
   "metadata": {
    "id": "da79ce2d"
   },
   "outputs": [],
   "source": [
    "# KNN Model\n",
    "\n",
    "# Select the top 20 most correlated features and store it in a list called 'top_20_features' (using similar correlation table from Task 1)\n",
    "\n",
    "top_20_features = ##### CODE HERE #####\n",
    "\n",
    "\n",
    "#For building the model, you must use X_train[top_20_features]\n",
    "\n",
    "##### CODE HERE #####\n",
    "\n",
    "\n",
    "\n",
    "# Find the value of k for which RMSE is minimum, using GridSearchCV\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5f15c",
   "metadata": {
    "id": "b0b5f15c"
   },
   "source": [
    "### 2.3\n",
    "*Summarize the predictive performance in terms of RMSE.* \n",
    "1. *Calculate the RMSE values for train and validation for all the models*\n",
    "2. *Display them in a tabulated format*\n",
    "\n",
    "Hint: You may use the code that you've learnt in the 'Model selection' module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec533b4a",
   "metadata": {
    "id": "ec533b4a"
   },
   "outputs": [],
   "source": [
    "#linear regression\n",
    "\n",
    "##### CODE HERE #####\n",
    "\n",
    "\n",
    "\n",
    "#max depth pruned tree\n",
    "\n",
    "##### CODE HERE #####\n",
    "\n",
    "\n",
    "\n",
    "#knn\n",
    "\n",
    "##### CODE HERE #####\n",
    "\n",
    "\n",
    "\n",
    "#Display the RMSEs\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40165e94",
   "metadata": {
    "id": "40165e94"
   },
   "source": [
    "### 2.4\n",
    "*Study the largest errors that you made (largest overpredictions, largest underpredictions). What may be some of the reasons why the model is over/under predicting? Do these insights possibly help you improve the models?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53519128",
   "metadata": {
    "id": "53519128"
   },
   "outputs": [],
   "source": [
    "# Visualize the errors - plot a scatterplot of the residuals vs the true SalePrice\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b007ee9",
   "metadata": {
    "id": "8b007ee9"
   },
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34e97d",
   "metadata": {
    "id": "fd34e97d"
   },
   "source": [
    "### 3.1\n",
    "*Are you able to improve your linear regression model by taking the log of the dependent variable? (remember to translate your predicted outcome back to the original units before calculating the RMSE)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3611aecb",
   "metadata": {
    "id": "3611aecb"
   },
   "source": [
    "*Create a visualization, that highlights the distribution of prices when after taking log of the dependent variable*\n",
    "\n",
    "Hint - You may use [numpy.log()](https://numpy.org/doc/stable/reference/generated/numpy.log.html) to get the log of the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196d5160",
   "metadata": {
    "id": "196d5160"
   },
   "outputs": [],
   "source": [
    "# distribution of the transformed SalePrice\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783d03f",
   "metadata": {
    "id": "4783d03f"
   },
   "outputs": [],
   "source": [
    "# Linear model - Using the log of the SalePrice as the dependent variable, run the LassoCV to obtain the best LASSO model\n",
    "# Note that the optimum value of Alpha for this model would also be scaled down to a log scale. It's a better idea to simply search for the best alpha once again using LassoCV.\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i1-mZsHXA2_U",
   "metadata": {
    "id": "i1-mZsHXA2_U"
   },
   "outputs": [],
   "source": [
    "# Calculate the RMSE values for train and the test set\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddoV85gA3es",
   "metadata": {
    "id": "3ddoV85gA3es"
   },
   "outputs": [],
   "source": [
    "# Display the RMSE values in a dataframe\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9adf7b",
   "metadata": {
    "id": "8a9adf7b"
   },
   "source": [
    "### 3.2 Bonus Task\n",
    "*Experiment with data segmentation: Should you subset the data and fit separate models for each subset?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d49a44",
   "metadata": {
    "id": "92d49a44"
   },
   "source": [
    "Data segmentation is generally useful when we think that subsegments of our data have substantially different relationships between their features and the outcome compared to other subsegments (i.e variable interactions). We can use a combination of prior knowledge and data exploration to build our domain knowledge about where this situation would apply.\n",
    "\n",
    "Starting with prior knowledge, you can hypothesize $HouseStyle$ may be a candidate for data segmentation, as for instance, 3 bedrooms in a 1-story house may have a different effect on $SalePrice$ than 3 bedrooms in a 2-story house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a906fb",
   "metadata": {
    "id": "59a906fb"
   },
   "outputs": [],
   "source": [
    "housing_df['House Style'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb88267",
   "metadata": {
    "id": "dbb88267"
   },
   "outputs": [],
   "source": [
    "housing_df['Bedroom AbvGr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IZRHdf_VKJ8X",
   "metadata": {
    "id": "IZRHdf_VKJ8X"
   },
   "outputs": [],
   "source": [
    "matrix = []\n",
    "styles = ['1Story', '2Story', '1.5Fin']\n",
    "for style in styles:\n",
    "    curr_style = []\n",
    "    for bedrooms in range(1, 6):\n",
    "        curr_mean = housing_df[(housing_df['House Style'] == style) & \n",
    "                               (housing_df['Bedroom AbvGr'] == bedrooms)]['SalePrice'].mean()\n",
    "        \n",
    "        curr_style.append(curr_mean)\n",
    "    matrix.append(curr_style)\n",
    "sns.heatmap(matrix)\n",
    "plt.ylabel('House Style')\n",
    "plt.yticks(np.arange(3)+0.5, styles)\n",
    "plt.xlabel('Bedroom AbvGr')\n",
    "plt.xticks(np.arange(5)+0.5, np.arange(5)+1)\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80eb073",
   "metadata": {
    "id": "d80eb073"
   },
   "source": [
    "We indeed see some interaction between the housing style and bedroom number, indicating data segmentation could be promising. \n",
    "\n",
    "*From here, it's your task to start building a linear model to see whether data segmentation will improve results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y3AVv5wtlbcA",
   "metadata": {
    "id": "Y3AVv5wtlbcA"
   },
   "source": [
    "Hint: For the first two subtasks in 3.2, you could run a for-loop for each style in HouseStyles and evaluate/create the LASSO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f4393",
   "metadata": {
    "id": "747f4393"
   },
   "outputs": [],
   "source": [
    "# Linear Full Model (FM) - Train a Lasso model for the whole dataset \n",
    "\n",
    "##### CODE HERE #####\n",
    "\n",
    "# Store the RMSE values of train and validation for all the 3 subsets of styles - You can loop through the HouseStyles\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9iZ-Fd_-3s5c",
   "metadata": {
    "id": "9iZ-Fd_-3s5c"
   },
   "outputs": [],
   "source": [
    "# Linear Data Segmentation Model (DSM) - Train a Lasso model for the individual subset of styles - 1Story, 2Story and 1.5Fin\n",
    "\n",
    "##### CODE HERE #####\n",
    "\n",
    "# Store the RMSE values of train and validation for all the 3 subsets of styles\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2da0e1",
   "metadata": {
    "id": "1e2da0e1"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the values of RMSE for both the models on the train and validation sets on all the 3 subsets of data\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fY-Yzk3z3xq7",
   "metadata": {
    "id": "fY-Yzk3z3xq7"
   },
   "source": [
    "*Write down your inferences about the performance of the subsetted model here -* \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803ba45e",
   "metadata": {
    "id": "803ba45e"
   },
   "source": [
    "# Task 4: Summarize your findings\n",
    "*Now take some time to translate your results into valuable insights.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6542ae0",
   "metadata": {
    "id": "e6542ae0"
   },
   "source": [
    "### 4.1\n",
    "*What drives housing prices? Find the top 20 major drivers.*\n",
    "\n",
    "Hint - In course 3 module 1, you have already seen how to store the coefficients of a model in a dictionary. You can convert the dictionary into a DataFrame and sort the dataframe by the coefficients. [Here's](https://stackoverflow.com/questions/18837262/convert-python-dict-into-a-dataframe) some guidance on how to convert dictionary into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c1c67d",
   "metadata": {
    "id": "e1c1c67d"
   },
   "outputs": [],
   "source": [
    "# Visualize all the columns and their coefficients sorted in descending order to understand the ones that has the most say in the SalePrice\n",
    "# Hint - Check the code for Course 3 Module 1 - Linear regression in a predictive setting to \n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AEwkNH-uOHhl",
   "metadata": {
    "id": "AEwkNH-uOHhl"
   },
   "source": [
    "*You can also use a built in variable importance function from decision trees to capture a summary of the importance of different features in our regression tree.* \n",
    "\n",
    "Note: There is no coding to be done in this cell. Just execute this cell and observe the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MmQBSolJOHM3",
   "metadata": {
    "id": "MmQBSolJOHM3"
   },
   "outputs": [],
   "source": [
    "# Extract the feature_importances_ attribute from the tree model (feature_importances_ is an attribute available in trained sklearn models)\n",
    "\n",
    "# Extracting the importances by sklearn (Replace tree_reg_best by the variable of your tree model)\n",
    "importances_sk = tree_reg_best.feature_importances_\n",
    "\n",
    "# Creating a dataframe with the feature importance by sklearn\n",
    "feature_importance_df = []\n",
    "for i, feature in enumerate(X_train.columns):\n",
    "    feature_importance_df.append([feature, round(importances_sk[i], 3)])\n",
    "   \n",
    "feature_importance_df = pd.DataFrame(feature_importance_df,\n",
    "                                     columns=['Feature', 'Importance'])\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "print(f\"Feature importance by sklearn: \")\n",
    "feature_importance_df.iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d228173",
   "metadata": {
    "id": "1d228173"
   },
   "source": [
    "### 4.2\n",
    "*What is the predictive performance of your models?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zq12ayCmG9Pp",
   "metadata": {
    "id": "zq12ayCmG9Pp"
   },
   "outputs": [],
   "source": [
    "# Compare the RMSE of the train and the validation set for all the models. You can reuse the code from exercise 2.3.\n",
    "\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CbsIRylpkNKF",
   "metadata": {
    "id": "CbsIRylpkNKF"
   },
   "source": [
    "*Which model performs the best?*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ae3f7",
   "metadata": {
    "id": "185ae3f7"
   },
   "source": [
    "### 4.3\n",
    "*How reliable are your predictions?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591fabf",
   "metadata": {
    "id": "7591fabf"
   },
   "outputs": [],
   "source": [
    "#Plot a scatterplot of the predicted vs the true value of the SalePrice\n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9eaff",
   "metadata": {
    "id": "66d9eaff"
   },
   "source": [
    "*A histogram of errors could also give a good insight on any underlying patterns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8777f8",
   "metadata": {
    "id": "3b8777f8"
   },
   "outputs": [],
   "source": [
    "#Plot a histogram of the residuals. \n",
    "\n",
    "##### CODE HERE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a070b84",
   "metadata": {
    "id": "4a070b84"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Housing_Case_Study_Stub.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
