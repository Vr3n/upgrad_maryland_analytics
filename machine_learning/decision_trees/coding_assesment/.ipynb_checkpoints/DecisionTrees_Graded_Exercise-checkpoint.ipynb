{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a845d97",
   "metadata": {
    "id": "mIEb3H8DUnjy"
   },
   "source": [
    "# Task 1 - Data Preparation\n",
    "For this task, you will perform the following steps:\n",
    "- Load all the necessary packages for this exercise\n",
    "- Load the data\n",
    "- Split the data into input features and the target variable\n",
    "- Split the data into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421b96a",
   "metadata": {
    "id": "a82e79ad"
   },
   "outputs": [],
   "source": [
    "# Import 'numpy' and 'pandas' to work with numbers and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import 'matplotlib.pyplot' for visualizations\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import method for train-validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import methods for building decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import 'GridSearchCV' for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import suitable performance metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09f763",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "a251d675",
    "outputId": "80cb8cc4-9d84-459c-a381-5ecf6d003770",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the data and take a look at it\n",
    "# Note: Make sure that the data is in the same folder as the Jupyter notebook or specify the address correctly\n",
    "teadata = pd.read_csv('MLTeaInc_DT.csv')\n",
    "teadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b8bc6",
   "metadata": {
    "id": "1572d3ad"
   },
   "outputs": [],
   "source": [
    "# Split the data into input features and the target variable\n",
    "# Note: The target variable here is the 'Preference' feature\n",
    "# Note: The class 'Unsweetened' is the class of interest or the positive class in this exercise\n",
    "X = ########## CODE HERE ##########\n",
    "y = ########## CODE HERE ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation and testing datasets using the 'train_test_split()' method\n",
    "# Hint: Study the documentation of the 'train_test_split()' method\n",
    "# Note: Use 'test_size = 0.5' and 'random_state = 0'\n",
    "X_train, X_val, y_train, y_val = ########## CODE HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a135f",
   "metadata": {
    "id": "e359ec34"
   },
   "source": [
    "# Task 2 - Building Classification Trees\n",
    "For this task, you will perform the following steps:\n",
    "- Build and analyze a basic decision tree model without any pruning\n",
    "- Build and analyze a decision tree model pruned using the *ccp_alpha* parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288f6f9",
   "metadata": {},
   "source": [
    "## Sub-task 1 - Decision Tree Model 1\n",
    "For this sub-task, you will perform the following steps:\n",
    "- Build a basic decision tree model without pruning\n",
    "- Visualize the confusion matrix for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf62e1d",
   "metadata": {
    "id": "6a328625"
   },
   "outputs": [],
   "source": [
    "# Train a decision tree without any pruning on the training data using the 'DecisionTreeClassifier()' method\n",
    "# Hint: Study the documentation of the 'DecisionTreeClassifier()' method\n",
    "# Note: Use 'random_state = 0'\n",
    "DT1 = ########## CODE HERE ##########\n",
    "DT1 = DT1.fit(########## CODE HERE ##########)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fd6fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZ_GnzxvSvXh",
    "outputId": "46a87817-99f1-4c9d-e0e5-a67146b82e49",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the number of leaves and the depth of the tree for 'DT1' using the 'get_n_leaves()' and the 'get_depth()' methods\n",
    "# Hint: Study the documentations of the 'get_n_leaves()' and the 'get_depth()' methods\n",
    "DT1_n_leaves = DT1.########## CODE HERE ##########\n",
    "DT1_depth = DT1.########## CODE HERE ##########\n",
    "print('Number of leaves =', DT1_n_leaves)\n",
    "print('Tree depth =', DT1_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc51be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "1390e8c4",
    "outputId": "042b0cc0-0f74-4ffd-b030-56ae9dde9753",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the confusion matrices for 'DT1' on the training and validation data\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(DT1, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
    "ConfusionMatrixDisplay.from_estimator(DT1, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
    "ax[0].set_title('Training')\n",
    "ax[1].set_title('Validation')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a50ec2",
   "metadata": {
    "id": "I16rSdM8vGz3"
   },
   "source": [
    "## Sub-task 2 - Decision Tree Model 2\n",
    "For this sub-task, you will perform the following steps:\n",
    "- Build a pruned decision tree using the *ccp_alpha* hyperparameter\n",
    "- Visualize the confusion matrix for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the cost complexity pruning path information from 'DT1' using the 'cost_complexity_pruning_path()' method\n",
    "# Hint: Study the documentation of the 'cost_complexity_pruning_path()' method\n",
    "path = DT1.########## CODE HERE ##########\n",
    "\n",
    "# Obtain the list of cost complexity alpha values from the path\n",
    "# Hint: Study the 'path' object and look for the 'ccp_alphas' attribute\n",
    "ccp_alpha_values = path.########## CODE HERE ##########\n",
    "\n",
    "# Create an empty list to store the tree models for each cost complexity alpha value\n",
    "DTs = []\n",
    "\n",
    "# Fit a decision tree model for each value of cost complexity alpha\n",
    "for ccp_alpha_value in ccp_alpha_values:\n",
    "\n",
    "    # Fit a tree model on the training data with the current cost complexity value using the 'DecisionTreeClassifier()' method\n",
    "    # Hint: The parameter 'ccp_alpha' needs to be set to the current cost complexity alpha value\n",
    "    # Note: Use 'random_state = 0'\n",
    "    curr_DT = ########## CODE HERE ##########\n",
    "    curr_DT = curr_DT.fit(########## CODE HERE ##########)\n",
    "\n",
    "    # Add the model to the list of models\n",
    "    DTs.append(curr_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the accuracy values for the trees in 'DTs' for the training and validation datasets\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "# Obtain training and validation accuracies for each tree in 'DTs'\n",
    "for DT in DTs:\n",
    "    # Obtain predicted class labels for the training and validation data using the current tree in 'DTs' using the 'predict()' method\n",
    "    y_train_pred = DT.########## CODE HERE ##########\n",
    "    y_val_pred = DT.########## CODE HERE ##########\n",
    "\n",
    "    # Compute and append the accuracy values for the training and validation datasets to the lists\n",
    "    # Hint: Study the documentation of the 'accuracy_score()' method\n",
    "    train_acc.append(accuracy_score(########## CODE HERE ##########))\n",
    "    val_acc.append(accuracy_score(########## CODE HERE ##########))\n",
    "\n",
    "# Print the value of the cost complexity parameter for which the validation accuracy is the highest\n",
    "# Hint: Obtain the index of the list 'val_acc' where the value of 'val_acc' is the highest\n",
    "# Hint: Use this index value to obtain the value of the corresponding cost complexity from the list 'ccp_alpha_values'\n",
    "best_ccp_alpha = ########## CODE HERE ##########\n",
    "print('Best CCP alpha: ', best_ccp_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21475726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree on the training data using the 'DecisionTreeClassifier()' method with the best 'ccp_alpha' value\n",
    "# Hint: The parameter 'ccp_alpha' needs to be set to 'best_ccp_alpha'\n",
    "# Note: Use 'random_state = 0'\n",
    "DT2 = ########## CODE HERE ##########\n",
    "DT2 = DT2.fit(########## CODE HERE ##########)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a68a6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8Yps8kN82s4",
    "outputId": "2fd27b80-b8bc-4ca3-f096-02e8b0c9e4fd"
   },
   "outputs": [],
   "source": [
    "# Print the number of leaves and the depth of the tree for 'DT2' using the 'get_n_leaves()' and the 'get_depth()' methods\n",
    "# Hint: Study the documentations of the 'get_n_leaves()' and the 'get_depth()' methods\n",
    "DT2_n_leaves = DT2.########## CODE HERE ##########\n",
    "DT2_depth = DT2.########## CODE HERE ##########\n",
    "print('Number of leaves =', DT2_n_leaves)\n",
    "print('Tree depth =', DT2_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrices for 'DT2' on the training and validation data\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(DT2, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
    "ConfusionMatrixDisplay.from_estimator(DT2, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
    "ax[0].set_title('Training')\n",
    "ax[1].set_title('Validation')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a422d4",
   "metadata": {},
   "source": [
    "# Task 3 - Comparing the Models\n",
    "For this task, you will perform the following steps:\n",
    "- Compare various classification performance metrics for the two models that you have built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print various classification performance measures for the two models on the training and validation data\n",
    "# Hint: You will need to obtain the predicted class labels for each of the two models using the 'predict()' method\n",
    "# Hint: You will need to obtain the predicted probabilities for each of the two models using the 'predict_proba()' method\n",
    "\n",
    "# Hint: Study the documentations of the different peformance metrics methods\n",
    "# Note: For F1 score, specify the 'pos_label' parameter as 'Unsweetened'\n",
    "\n",
    "# Compute predicted probabilities and class labels for each of the models on the training and validation data\n",
    "# Hint: The second column of the matrix returned by the 'predict_proba()' method contains the positive class probabilities\n",
    "\n",
    "train_probabilities_1 = DT1.########## CODE HERE ##########\n",
    "val_probabilities_1 = DT1.########## CODE HERE ##########\n",
    "train_y_pred_1 = DT1.########## CODE HERE ##########\n",
    "val_y_pred_1 = DT1.########## CODE HERE ##########\n",
    "\n",
    "train_probabilities_2 = DT2.########## CODE HERE ##########\n",
    "val_probabilities_2 = DT2.########## CODE HERE ##########\n",
    "train_y_pred_2 = DT2.########## CODE HERE ##########\n",
    "val_y_pred_2 = DT2.########## CODE HERE ##########\n",
    "\n",
    "# Use the predicted class labels to compute the following performance metrics\n",
    "\n",
    "# Compute the accuracies\n",
    "train_acc_1 = accuracy_score(########## CODE HERE ##########)\n",
    "val_acc_1 = accuracy_score(########## CODE HERE ##########)\n",
    "train_acc_2 = accuracy_score(########## CODE HERE ##########)\n",
    "val_acc_2 = accuracy_score(########## CODE HERE ##########)\n",
    "\n",
    "# Compute the F1 scores\n",
    "train_f1_1 = f1_score(########## CODE HERE ##########)\n",
    "val_f1_1 = f1_score(########## CODE HERE ##########)\n",
    "train_f1_2 = f1_score(########## CODE HERE ##########)\n",
    "val_f1_2 = f1_score(########## CODE HERE ##########)\n",
    "\n",
    "# Use the predicted probabilities to compute the ROC AUC scores\n",
    "\n",
    "# Compute the ROC AUC scores\n",
    "train_auc_1 = roc_auc_score(########## CODE HERE ##########)\n",
    "val_auc_1 = roc_auc_score(########## CODE HERE ##########)\n",
    "train_auc_2 = roc_auc_score(########## CODE HERE ##########)\n",
    "val_auc_2 = roc_auc_score(########## CODE HERE ##########)\n",
    "\n",
    "# Summarize the above metrics for all four models using a single data frame and display it\n",
    "modelcompare = pd.DataFrame(data = {'Training Accuracy': [train_acc_1, train_acc_2],\n",
    "                                    'Validation Accuracy': [val_acc_1, val_acc_2],\n",
    "                                    'Training F1 Score': [train_f1_1, train_f1_2],\n",
    "                                    'Validation F1 Score': [val_f1_1, val_f1_2],\n",
    "                                    'Training ROC AUC Score': [train_auc_1, train_auc_2],\n",
    "                                    'Validation ROC AUC Score': [val_auc_1, val_auc_2]},\n",
    "                            index = ['DT1', 'DT2'])\n",
    "\n",
    "modelcompare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a8d1c5",
   "metadata": {},
   "source": [
    "# Task 4 - Misclassification Costs of Suitable Model\n",
    "For this task, you will perform the following steps:\n",
    "- Select a model based on their classification performance measures\n",
    "- Compute the baseline misclassification cost\n",
    "- Obtain the best misclassification cost and the associated cut-off from the training data\n",
    "- Compute the potentially best misclassification cost of the model using the validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d7951",
   "metadata": {},
   "source": [
    "Note: Suppose that the problem statement requires that your classification model satisfies the following conditions:\n",
    "- The absolute value of the difference between the training and the validation accuracies is less than 0.2\n",
    "- The validation accuracy is greater than 0.7\n",
    "- The absolute value of the difference between the training and the validation ROC AUC scores is less than 0.2\n",
    "- The validation ROC AUC score is greater than 0.7\n",
    "- The validation F1 score is greater than 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b34053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the conditions on the performance measures, select the better model\n",
    "# Hint: Use the 'modelcompare' data frame that you created to obtain the name of the best model\n",
    "best_model_name = modelcompare[########## CODE HERE ##########].index[0]\n",
    "\n",
    "print('The model better suited to the conditions of the problem statement is \"{}\".'.format(best_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcbcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the cost of false positives and false negatives\n",
    "# Note: The model will be used to send invitations to customers who potentially prefer unsweetened tea for a reveal party\n",
    "# Note: The cost of false positives and false negatives are provided to you for this exercise\n",
    "# Note: Labeling a customer who prefers sweetened tea as 'Unsweetened' leads to just sending a wrong invitation, so its cost is less\n",
    "# Note: Labeling a customer who prefers unsweetened tea as 'Sweetened' leads to losing out on a potential customer, so its cost is more\n",
    "fp_cost = 300\n",
    "fn_cost = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd8547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the misclassification cost for the naive model on the training and the validation data\n",
    "# Hint: The naive model in this case would classify everyone as preferring unsweetened tea or class 'Unsweetened'\n",
    "# Hint: That means all class 'Unsweetened' people are classified as class 'Unsweetened' accurately\n",
    "# Hint: The class 'Sweetened' people are the only ones that contribute to the misclassification\n",
    "# Hint: So, you need to count how many 'y_train' and 'y_val' values are actually class 'Sweetened', since all of them are labeled as class 'Unsweetened'\n",
    "# Hint: Recall the formula for the misclassification cost\n",
    "train_mc_cost_0 = ########## CODE HERE ##########\n",
    "val_mc_cost_0 = ########## CODE HERE ##########\n",
    "\n",
    "print('The misclassification cost of classifying everyone in the training data as preferring unsweetened tea = {} dollars'.format(train_mc_cost_0))\n",
    "print('The misclassification cost of classifying everyone in the validation data as preferring unsweetened tea = {} dollars'.format(val_mc_cost_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of misclassification costs for various cut-off values for the selected tree model on the training and the validation data\n",
    "# Hint: If the 'train_probabilities' or the 'val_probabilities' value is greater than the cut-off, then the label is class 'Unsweetened', else it's class 'Sweetened'\n",
    "# Hint: Try using the 'np.where()' method to obtain the predictions for each cut-off value\n",
    "# Hint: Study the documentation of the 'confusion_matrix()' method to obtain the false positive and false negative counts\n",
    "# Hint: Recall the formula for the misclassification cost\n",
    "train_mc_cost = []\n",
    "val_mc_cost = []\n",
    "cutoffs = np.arange(0, 1, 0.01)\n",
    "for cutoff in cutoffs:\n",
    "    train_y_pred = ########## CODE HERE ##########\n",
    "    train_curr_cf = confusion_matrix(########## CODE HERE ##########)\n",
    "    train_fp_count = ########## CODE HERE ##########\n",
    "    train_fn_count = ########## CODE HERE ##########\n",
    "    train_mc_cost_current = ########## CODE HERE ##########\n",
    "    train_mc_cost.append(train_mc_cost_current)\n",
    "    \n",
    "    val_y_pred = ########## CODE HERE ##########\n",
    "    val_curr_cf = confusion_matrix(########## CODE HERE ##########)\n",
    "    val_fp_count = ########## CODE HERE ##########\n",
    "    val_fn_count = ########## CODE HERE ##########\n",
    "    val_mc_cost_current = ########## CODE HERE ##########\n",
    "    val_mc_cost.append(val_mc_cost_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cut-off associated with the minimum misclassification cost on the training data to get the best cost for the validation data\n",
    "# Hint: The expected best misclassification cost on the validation data is the cost associated with the best cut-off from the training data\n",
    "# Note: The best cut-off for the training data is the cut-off associated with the minimum misclassification cost for the training data\n",
    "val_best_cost = ########## CODE HERE ##########\n",
    "\n",
    "print('Best misclassification cost on the validation data for the model = {} dollars'.format(val_best_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a12357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C3M4_v4b.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
