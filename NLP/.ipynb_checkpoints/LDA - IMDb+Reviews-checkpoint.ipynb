{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pJA_S4utbGhlOHbPsjY1OqEY7jVS4uij","timestamp":1666077231256},{"file_id":"172xIrkG-RCBBkL8lci0Ev0n5tnOt2X5U","timestamp":1665472772865},{"file_id":"1VsOaFNMLq5Mm10gf59U8anR9wcipo_89","timestamp":1619505201784}],"collapsed_sections":["AnfFO0YljcjT"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","source":["# Session 2: Comprehension - LDA\n","\n","\n"],"metadata":{"id":"JUuzSQYTJaXz"}},{"cell_type":"markdown","metadata":{"_uuid":"1424638f5259100af9f9a5c1b05bd23cf5b71e51","id":"LonRsbKYNrGB"},"source":["### Import libraries"]},{"cell_type":"markdown","metadata":{"id":"v5ulho010zoj"},"source":["To start off, you will import the required libraries for visualising and analysing the text data.\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"vLlQYM1rU0Nl"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"PS0ezMQKNrGB"},"source":["# Import libraries\n","import pandas as pd\n","import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","nltk.download('punkt')\n","nltk.download('omw-1.4')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LDA"],"metadata":{"id":"AnfFO0YljcjT"}},{"cell_type":"markdown","source":["#1. Load the data"],"metadata":{"id":"LObmYHIGNpYy"}},{"cell_type":"markdown","metadata":{"id":"hrx-uD9LF8sW"},"source":["##### Method 1 - Google Colab\n","- Run the code block below if you're using Google colab for this demonstration and have uploaded the papers.csv file in your Google Drive\n","- Else, skip this part and move to the next cell block and run it in case you're using Jupyter "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQObP1-Ae24g","outputId":"6dec3217-f5da-4b4a-b58e-fa7dd6324788"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Mount your Google drive that you can access files located in your Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leV6_P4-ToVz"},"outputs":[],"source":["# Read the files into a data frame using the function read_csv in pandas\n","import pandas as pd\n","imdb = pd.read_csv('/content/drive/MyDrive/IMDB_reviews_LDA.csv',header=0).sample(6000, random_state=123) # the first row will be the header\n","imdb.head() # show the first 5 rows (5 by default)"]},{"cell_type":"markdown","metadata":{"id":"_fMdPgu5F8sd"},"source":["###### Method 2 - Jupyter Notebook\n","- Run the code block below if you're using Jupyter Notebook on your local machine"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_iUoF2VsF8se"},"outputs":[],"source":["import pandas as pd\n","imdb = pd.read_csv('IMDB_reviews_LDA.csv').sample(6000, random_state=123)\n","imdb.head()"]},{"cell_type":"markdown","source":["# 2. EDA\n","\n","Question 1: Which of the following can be treated as potential stop words from the word cloud results of the IMDb reviews? (Note: More than one option may be correct.)\n","\n","Hint: High frequent words that don't add much value to the context can be considered stopwords."],"metadata":{"id":"mS3GAd1khBx9"}},{"cell_type":"code","source":["# Import the wordcloud library\n","from wordcloud import WordCloud\n","\n","# Join the different processed titles together.\n","long_string = ','.join(list(imdb['review'].values))\n","\n","# Create a WordCloud object\n","wordcloud = WordCloud(#write your code here)\n","\n","# Generate a word cloud\n","wordcloud.generate(long_string)\n","\n","# Visualize the word cloud\n","wordcloud.to_image()"],"metadata":{"id":"1HiUZqjMgctO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. LDA analysis"],"metadata":{"id":"jgy7NMsihJCU"}},{"cell_type":"markdown","source":["#### 3.1 Import libraries"],"metadata":{"id":"sUnfT1s3hJCU"}},{"cell_type":"code","source":["import gensim\n","from gensim.utils import simple_preprocess\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords"],"metadata":{"id":"tRoYgJP9hJCU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3.2 Tokenization"],"metadata":{"id":"Q5BO2qH6hJCU"}},{"cell_type":"code","source":["# Tokenizing sentences into words\n","def sent_to_words(sentences):\n","    for sentence in sentences:\n","        # deacc=True removes punctuations\n","        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"],"metadata":{"id":"z5yi8mERhJCU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3.3 Stopwords removal"],"metadata":{"id":"KGP_jpsUhJCV"}},{"cell_type":"code","source":["stop_words = stopwords.words('english')\n","stop_words.extend(['movie', 'film', 'one', 'even'])\n","\n","def remove_stopwords(texts):\n","    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n"],"metadata":{"id":"8syFKL9JhJCV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = imdb.review.values.tolist()\n","data_words = list(sent_to_words(data))\n","\n","# remove stop words\n","data_words = remove_stopwords(data_words)\n","\n","print(data_words[:1][0][:10])\n","print(data_words[1:2][0][:10])"],"metadata":{"id":"_AD6imS3hJCV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#4. Term document freqency\n","\n","Question 2: How many words have a frequency of >1 for the first document example in the corpus of document examples? "],"metadata":{"id":"o8cChfseiWvr"}},{"cell_type":"code","source":["import gensim.corpora as corpora\n","\n","# Create Dictionary\n","id2word = corpora.Dictionary(data_words)\n","\n","# Create Corpus\n","texts = data_words\n","\n","# Term Document Frequency\n","corpus = [id2word.doc2bow(text) for text in texts]\n","\n","# View the term frequency of first 10 features of the first document\n","print(corpus[:1][0][:10])"],"metadata":{"id":"JHRtFL_LiWvz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code to find the number of features in first document that have a frequency > 1\n","\n","count=0\n","\n","for feature,frequency in corpus[0]:\n","  if frequency>1:\n","    count=count+1\n","\n","print(count)\n"],"metadata":{"id":"WaQqEQwqAgEA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#5. Training the model\n","Question 3:  In what range does the perplexity score fall for your LDA model (eta = 0.01)?\n","\n","Question 4:  Suppose you decrease the value of the eta while training the LDA model. How does the value of the log perplexity change?"],"metadata":{"id":"T9KcNA_4iWvz"}},{"cell_type":"code","source":["from pprint import pprint\n","import numpy as np \n","\n","# number of topics\n","num_topics = 10\n","\n","# Build LDA model\n","lda_model = #write your code here"],"metadata":{"id":"fpxhsVariWvz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. Model Output"],"metadata":{"id":"sS_MqxIQiWvz"}},{"cell_type":"code","source":["doc_lda = lda_model[corpus]\n","for i in range(len(texts)):\n","  docbow = corpus[i]\n","  doc_topics = lda_model.get_document_topics(docbow,minimum_probability=0.0)\n","  doc_topic_prob = np.array([v[1] for v in doc_topics])\n","  print('review:',i+1,', dominant topic:',np.argmax(doc_topic_prob)+1)"],"metadata":{"id":"xXaXsLS8iWvz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8. Model Evaluation"],"metadata":{"id":"U9L2WK9BiWv0"}},{"cell_type":"code","source":["# Calculate and return per-word likelihood bound, using a chunk of documents as evaluation corpus.\n","# Also output the calculated statistics, including the perplexity=2^(-bound), to log at INFO level.\n","\n","perplexity_score = # write your code here\n","print('Perplexity score: ', perplexity_score)"],"metadata":{"id":"kChhqwZlgc-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0yNioKVLgdFD"},"execution_count":null,"outputs":[]}]}